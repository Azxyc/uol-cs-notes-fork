I"<p>Adversarial search is a method of reaching a goal while making moves against another player. This allows the agent to react to the moves of another player.</p>

<p>In search we make all moves. In games we play against an unpredictable opponent:</p>

<ul>
  <li>Solution is a strategy  specifying a move for every possible move of the opponent.</li>
  <li>A method is need for selecting good moves that stand a good chance of achieving a winning state whatever the opponent does.</li>
  <li>Because of combinatorial explosion, in practice we must approximate using heuristics.</li>
</ul>

<h2 id="types-of-games">Types of Games</h2>

<ul>
  <li>Information
    <ul>
      <li>In some games we have fully observable environment. These are called games with prefect information.</li>
      <li>In others we have partially observable environments. These are called games with imperfect information.</li>
    </ul>
  </li>
  <li>Determinism
    <ul>
      <li>Some games are deterministic</li>
      <li>Other games have an element of chance.</li>
    </ul>
  </li>
</ul>

<p>In addition we will limit ourselves to two-player games, with a zero-sum. This means:</p>

<ul>
  <li>The utility values at the end are equal and opposite</li>
  <li>If one player wins then the other player loses.</li>
</ul>

<p>As a result we can calculate a perfect strategy for the player.</p>

<h2 id="problem-formulation">Problem Formulation</h2>
<p>The difference between single player searches and adversarial search is that the set of goal states are replace by the <strong>utility function</strong>.</p>

<ul>
  <li>Initial state $S_{start}$
    <ul>
      <li>Initial board position. Which player moves first.</li>
    </ul>
  </li>
  <li>Successor function
    <ul>
      <li>Provides for every state $s$ and move the new state after the move.</li>
    </ul>
  </li>
  <li>Terminal test
    <ul>
      <li>Determines when the game is over.</li>
    </ul>
  </li>
  <li>Utility function
    <ul>
      <li>Numeric value for terminal states
        <ul>
          <li>E.g. chess $+1,-1,0$</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="game-tree">Game Tree</h3>
<ul>
  <li>Each level labelled with player to move.</li>
  <li>Each level represents a ply.
    <ul>
      <li>Half a turn.</li>
    </ul>
  </li>
  <li>Represents whit happen with competing agents.</li>
</ul>

<h2 id="minimax-algorithm">minimax Algorithm</h2>
<p>MIN and MAX are two players</p>

<ul>
  <li>MAX want to win (maximise utility)</li>
  <li>Min wants to MAX to lose (minimise utility for MAX)</li>
  <li>MIN is the opponent</li>
</ul>

<p>Both players will play to the best of their ability</p>

<ul>
  <li>MAX wants a strategy for maximising utility assuming MIN will do best to minimise MAXâ€™s utility.</li>
  <li>Considers the minimax value of each state
    <ul>
      <li>The utility of a state given that both players play optimally.</li>
    </ul>
  </li>
</ul>

<h3 id="minimax-value">minimax Value</h3>

<ul>
  <li>The utility (=minimax value) of a <strong>terminal state</strong> is given by its utility already (as an input).</li>
  <li>The utility (=minimaxvalue) of a <strong>MAX-state</strong> (when MAX moves) is the maximum of the utilities of its successor states.</li>
  <li>The utility (=minimax value) of <strong>MIN-state</strong> (when MIN moves) is the minimum of the utilities of its successor states.</li>
</ul>

<p>Thus we can compute the minimax value recursively starting from the terminal states.</p>

<p>Formally, let $\text{Succ}(s)$ denote the set of successor state of state $s$. Define the function $\text{MinimaxV}(s)$ recursively as follows:</p>

\[\text{MinimaxV}(s)=
\begin{cases}
	\text{Utility}(s) &amp; s\ \text{is terminal}\\
	\max_{n\in\text{Succ}(s)}\text{MinimaxV}(n) &amp; \max\text{moves in}\ s\\
	\min_{n\in\text{Succ}(s)}\text{MinimaxV}(n) &amp; \min\text{moves in}\ s
\end{cases}\]

<ul>
  <li>Calculate minimax value of each state using the equation above starting from the terminal states.</li>
  <li>Games tree as minimax tree
    <ul>
      <li>$\bigtriangleup$ max node, $\bigtriangledown$ min node</li>
    </ul>
  </li>
</ul>

<pre><code class="language-mermaid">graph TD
subgraph MAX
A0
end
subgraph MIN
A1
A2
A3
end
subgraph MAX
A11
A21
A31
A12
A22
A32
A13
A23
A33
end
A0[3] --&gt;|A1| A1[3]
A0 --&gt;|A2| A2[2]
A0 --&gt;|A3| A3[2]
A1 --&gt;|A11| A11[3]
A1 --&gt;|A12| A12[12]
A1 --&gt;|A13| A13[8]
A2 --&gt;|A21| A21[2]
A2 --&gt;|A22| A22[4]
A2 --&gt;|A23| A23[6]
A3 --&gt;|A31| A31[14]
A3 --&gt;|A32| A32[5]
A3 --&gt;|A33| A33[2]

</code></pre>

<h3 id="properties-of-minimax">Properties of minimax</h3>
<p>Assuming MAX always moves to the state with the maximal minimax value.</p>

<ul>
  <li>Optimal
    <ul>
      <li>Against an optimal opponent. Otherwise MAX will do even better. There may however, be better strategies against suboptimal opponents.</li>
    </ul>
  </li>
  <li>Time complexity
    <ul>
      <li>Can be implemented DFS so that space complexity is $b^m$ (branching factor $b$, depth $m$).</li>
    </ul>
  </li>
  <li>Space complexity
    <ul>
      <li>can be implemented DFS so that space complexity is $bm$.</li>
    </ul>
  </li>
</ul>

<p>For chess, $b\approx 35,\ m\approx 100$ for reasonable games.</p>

<ul>
  <li>10^154 paths to explore</li>
  <li>Infeasible</li>
</ul>

<p>But do we need to explore every path?</p>
:ET