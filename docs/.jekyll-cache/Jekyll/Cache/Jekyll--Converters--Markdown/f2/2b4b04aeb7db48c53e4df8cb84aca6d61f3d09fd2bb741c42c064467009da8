I"n<p>Entities that are engineered in AI are known as agents.</p>

<hr />
<p>@figure
An agent is anything that can be viewed as perceiving its environment through sensors and acting upon that environment through actuators.
@/
—</p>

<h2 id="peas">PEAS</h2>
<ul>
  <li>Performance Measure
    <ul>
      <li>The criteria by which we can measure the success of an agent’s behaviour.</li>
    </ul>
  </li>
  <li>Environment
    <ul>
      <li>The external environment that the agent inhabits.</li>
    </ul>
  </li>
  <li>Actuators
    <ul>
      <li>The means by which the agent acts within its environment.</li>
    </ul>
  </li>
  <li>Sensors
    <ul>
      <li>The means by which the agent senses its environment.</li>
    </ul>
  </li>
</ul>

<h3 id="ex-vacuum-cleaner">Ex. Vacuum Cleaner</h3>
<ul>
  <li>Performance measure
    <ul>
      <li>Clean all rooms quickly</li>
    </ul>
  </li>
  <li>Environment
    <ul>
      <li>A vacuum cleaner located in one of two rooms, each possibly containing dirt</li>
    </ul>
  </li>
  <li>Actuators
    <ul>
      <li>Move left/right, suck up the dirt, do nothing</li>
    </ul>
  </li>
  <li>Sensors
    <ul>
      <li>In which room is the vacuum cleaner? Is there dirt in that room?</li>
    </ul>
  </li>
</ul>

<h2 id="task-environments">Task Environments</h2>
<h3 id="fully-observable-vs-partially-observable">Fully Observable vs Partially Observable</h3>
<p>A fully observable environment is one in which the agent can fully obtain complete, up-to-date info about the environment’s state. Generally games can be fully observable but most real-life situations are partially observable.</p>

<p>Partially observable environments require a memory to deduce what might happen based on the last gained information.</p>

<h3 id="deterministic-vs-stochastic">Deterministic vs Stochastic</h3>
<p>Deterministic environments are where any action has a single guaranteed effect. Stochastic means that there is no certainty about the outcome given a certain input.</p>

<h3 id="episodic-vs-sequential">Episodic vs Sequential</h3>
<p>Episodic environments are where the performance of an agent is dependent on a number of discrete episodes with no link between it’s performance in each episode. In sequential environments different episodes are linked.</p>

<p>In sequential environments decisions made now may affect the future and must be taken into account.</p>

<h3 id="static-vs-dynamic">Static vs Dynamic</h3>
<p>In a static environment everything will stay the same while the agent is deliberating. This is common in turn based games. For dynamic environments things will change while the agent is deliberating and actions are more urgent.</p>
<h3 id="discrete-vs-continuous">Discrete vs Continuous</h3>
<p>In a discrete environment there are a fixed number of distinct states. In continuous environments there can be many states such that we consider them as infinite.</p>
:ET