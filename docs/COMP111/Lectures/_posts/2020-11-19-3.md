---
title: COMP111 - Bayes' Theorem
tags: COMP111 Lectures
---
## First Form
If `{% raw %}\(P(A)>0\){% endraw %}`, then:

`{% raw %}\[P(B\vert A)=\frac{P(A\vert B)\times P(B)}{P(A)}\]{% endraw %}`

### Proof
We have:

* `{% raw %}\(P(A\cap B)=P(A\vert B)\times P(B)\){% endraw %}`
* `{% raw %}\(P(A\cap B)=P(B\vert A)\times P(A)\){% endraw %}`

Thus:

`{% raw %}\[P(A\vert B)\times P(B)=P(B\vert A)\times P(A)\]{% endraw %}`

By dividing by `{% raw %}\(P(A)\){% endraw %}` we get:

`{% raw %}\[P(B\vert A)=\frac{P(A\vert B)\times P(B)}{P(A)}\]{% endraw %}`

### Application - Diagnosis
Assume a patient walks into a doctor's office complaining of a stiff neck. The doctor knows:

* Meningitis may cause a patient to have a stiff neck 50% of the time.
	* Causal knowledge.
* The probability of having meningitis is `{% raw %}\(\frac{1}{50000}\){% endraw %}`
* The probability of having a stiff neck is `{% raw %}\(\frac{1}{20}\){% endraw %}`

What is the probability that the patient has meningitis?

Let `{% raw %}\(A\){% endraw %}` be the event that the patient has a stiff neck and `{% raw %}\(B\){% endraw %}` the event that they have meningitis:

`{% raw %}\[P(B\vert A)=\frac{P(A\vert B)\times P(B)}{P(A)}=\frac{\frac{1}{2}\times \frac{1}{50000}}{\frac{1}{20}}=\frac{1}{5000}\]{% endraw %}`

* We can interpret the fact that the patient has a stiff neck as a new **observation**.
* Given this observation, we want to **classify** that patient as either having meningitis or not having meningitis.
* We have **prior** knowledge about the **unconditional** probability of having a stiff neck.
* We have **causal** knowledge about the number of times in which meningitis causes a stiff neck.
* We can then compute the diagnostic probabilities using: 

	`{% raw %}\[P(B\vert A)=\frac{P(A\vert B)\times P(B)}{P(A)}\]{% endraw %}`
	
## Alternative Form
You may not have the prior probability for `{% raw %}\(A\){% endraw %}` (the observation). In this case you can use other things that you might know in this alternative form.

If `{% raw %}\(P(A)>0\){% endraw %}`, then:

`{% raw %}\[P(B\vert A)=\frac{P(A\vert B)\times P(B)}{P(A\vert B)\times P(B)+P(A\vert \neg B)\times P(\neg B)}\]{% endraw %}`

### Proof
It suffices to show:

`{% raw %}\[P(A)=P(A\vert B)\times P(B)+P(A\vert \neg B) \times P(\neg B)\]{% endraw %}`

But this follows from:

`{% raw %}\[
\begin{aligned}
P(A)&=P((A\cap B)\cup (A\cap \neg B))\\
&=P(A\cap B)+P(A\cap\neg B)\\
&=P(A\vert B)\times P(B)+P(A\vert \neg B)\times P(\neg B)
\end{aligned}
\]{% endraw %}`

### Application - Diagnosis
Assume a drug test is:

* Positive for users 99% of the time.
* Negative for non-users 99% of the time.

Assume that 0.5% take the drug.

What is the probability that a person whose test is positive (event `{% raw %}\(A\){% endraw %}`) takes the drug (event `{% raw %}\(B\){% endraw %}`)?

We have:

* `{% raw %}\(P(A\vert B)=\frac{99}{100}\){% endraw %}`
* `{% raw %}\(P(\neg A\vert \neg B)=\frac{99}{100}\){% endraw %}`
* `{% raw %}\(P(B)=\frac{1}{200}\){% endraw %}`

Thus:

* `{% raw %}\(P(A\vert \neg B) =\frac{1}{100}\){% endraw %}`
* `{% raw %}\(P(\neg B) =\frac{199}{200}\){% endraw %}`

Thus:

`{% raw %}\[P(B\vert A)=\frac{P(A\vert B)\times P(B)}{P(A\vert B)\times P(B)+P(A\vert \neg B)\times P(\neg B)}=\frac{99}{298}\approx0.33\]{% endraw %}`

Due to the low value it means that it is hard to take an action based on the test. This is as a result of the low value of the people who take the drug. This results in many false positives for those that don't.
