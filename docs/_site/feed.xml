<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="http://localhost:4000/UoL/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/UoL/" rel="alternate" type="text/html" /><updated>2020-11-20T17:53:29+00:00</updated><id>http://localhost:4000/UoL/feed.xml</id><title type="html">Uni Notes</title><subtitle>A site containing my notes for all my modules taken at the University of Liverpool.
</subtitle><author><name>Ben Weston</name><email>b.weston60@gmail.com</email></author><entry><title type="html">COMP107 - Tutorial 3</title><link href="http://localhost:4000/UoL/comp107/tutorials/2020/11/20/1.html" rel="alternate" type="text/html" title="COMP107 - Tutorial 3" /><published>2020-11-20T00:00:00+00:00</published><updated>2020-11-20T00:00:00+00:00</updated><id>http://localhost:4000/UoL/comp107/tutorials/2020/11/20/1</id><content type="html" xml:base="http://localhost:4000/UoL/comp107/tutorials/2020/11/20/1.html">&lt;h2 id=&quot;designing-an-er-schema&quot;&gt;Designing an ER Schema&lt;/h2&gt;
&lt;p&gt;You should identify basic components:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Entity types, relationship types, attributes:
    &lt;ul&gt;
      &lt;li&gt;Key attributes.&lt;/li&gt;
      &lt;li&gt;Cardinality and participation constrains of relationships.&lt;/li&gt;
      &lt;li&gt;Different entity types.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There are also weak entities such as tables or chairs. These simple objects don’t need individual identification and should be a child of the strong entity.&lt;/p&gt;

&lt;p class=&quot;info&quot;&gt;The &lt;a href=&quot;.pdf&quot;&gt;lecture slides&lt;/a&gt; have a summary and examples of the ER diagram scheme.&lt;/p&gt;

&lt;h2 id=&quot;evolutionary-data-modelling&quot;&gt;Evolutionary Data Modelling&lt;/h2&gt;

&lt;p&gt;Evolutionary data modelling is an approach that proceeds in an incremental manner:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;An initial slim model is created that satisfies some initial requirements.&lt;/li&gt;
  &lt;li&gt;The model is then refines in a set of iterations adding details.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;exercise&quot;&gt;Exercise&lt;/h2&gt;
&lt;p&gt;Draw an ER model to describe the data need by the conference planner app starting from users stories:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;3 iterations with 8 minutes each.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;task-1&quot;&gt;Task 1&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;As a speaker, I want to upload the details of my keynote.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;As a speaker I want to know then my keynote is scheduled.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;2020-11-20-1-1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;task-2&quot;&gt;Task 2&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;As a participant I want to register my attendance to a keynote.&lt;/li&gt;
  &lt;li&gt;As a participant I want to book a room in a hotel.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;2020-11-20-1-2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;task-3&quot;&gt;Task 3&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;As an organiser, I want to know which conference participants are giving keynotes.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;2020-11-20-1-3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;tutor-review&quot;&gt;Tutor Review&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Speaker or not is redundant as it is implied by the fact they are presenting or not.&lt;/li&gt;
  &lt;li&gt;This is the same for the list of speakers. As it can be derived as a query&lt;/li&gt;
  &lt;li&gt;The organiser doesn’t need to be represented as they are just querying.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;final-diagram-after-review&quot;&gt;Final diagram after review:&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;2020-11-20-1-4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;</content><author><name>Ben Weston</name><email>b.weston60@gmail.com</email></author><category term="COMP107" /><category term="Tutorials" /><category term="COMP107" /><category term="Tutorials" /><summary type="html">Designing an ER Schema You should identify basic components: Entity types, relationship types, attributes: Key attributes. Cardinality and participation constrains of relationships. Different entity types. There are also weak entities such as tables or chairs. These simple objects don’t need individual identification and should be a child of the strong entity. The lecture slides have a summary and examples of the ER diagram scheme. Evolutionary Data Modelling Evolutionary data modelling is an approach that proceeds in an incremental manner: An initial slim model is created that satisfies some initial requirements. The model is then refines in a set of iterations adding details. Exercise Draw an ER model to describe the data need by the conference planner app starting from users stories: 3 iterations with 8 minutes each. Task 1 As a speaker, I want to upload the details of my keynote. As a speaker I want to know then my keynote is scheduled. Task 2 As a participant I want to register my attendance to a keynote. As a participant I want to book a room in a hotel. Task 3 As an organiser, I want to know which conference participants are giving keynotes. Tutor Review Speaker or not is redundant as it is implied by the fact they are presenting or not. This is the same for the list of speakers. As it can be derived as a query The organiser doesn’t need to be represented as they are just querying. Final diagram after review:</summary></entry><entry><title type="html">COMP105 - Lecture 18-1</title><link href="http://localhost:4000/UoL/comp105/lectures/2020/11/19/1.html" rel="alternate" type="text/html" title="COMP105 - Lecture 18-1" /><published>2020-11-19T00:00:00+00:00</published><updated>2020-11-19T00:00:00+00:00</updated><id>http://localhost:4000/UoL/comp105/lectures/2020/11/19/1</id><content type="html" xml:base="http://localhost:4000/UoL/comp105/lectures/2020/11/19/1.html">&lt;h2 id=&quot;marks-to-report-example&quot;&gt;Marks to Report Example&lt;/h2&gt;
&lt;p&gt;This lecture covers a mini assignment example about converting a csv file containing students marks into a report containing the students averages. These are presented in the following format:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-csv&quot;&gt;aaa		70	65	67	60
bbb		55	60	55	65
ccc		40	40	40	40
ddd		80	60	75	60
ccc		0	0	0	100
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And should be transformed to be:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-csv&quot;&gt;aaa		65.5
bbb		58.75
ccc		40.0
ddd		68.75
ccc		25.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p class=&quot;info&quot;&gt;See the &lt;a href=&quot;COMP105201119-1.pdf&quot;&gt;slides&lt;/a&gt; for the full examples.&lt;/p&gt;

&lt;h3 id=&quot;reading-files-in-haskell&quot;&gt;Reading files in Haskell&lt;/h3&gt;
&lt;p&gt;We can read a file using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;readFile&lt;/code&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;This is an IO function.&lt;/li&gt;
  &lt;li&gt;We will study this in more detail later on.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-haskell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;readfile&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;marks.csv&quot;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;aaa		70	65	67	60&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;bbb		55	60	55...
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\n&lt;/code&gt; character is the newline character.&lt;/p&gt;

&lt;h3 id=&quot;lines&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lines&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The lines function takes a string containing multiple lines into a list of strings. The complement to this function is the function &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;unlines&lt;/code&gt;. This will do the opposite.&lt;/p&gt;

&lt;h3 id=&quot;parsing-the-file&quot;&gt;Parsing the File&lt;/h3&gt;
&lt;p&gt;Using the functions &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;words&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lines&lt;/code&gt; we can put the file into a list of lists of strings, in order to process the file.&lt;/p&gt;

&lt;h3 id=&quot;getting-the-averages&quot;&gt;Getting the Averages&lt;/h3&gt;
&lt;p&gt;The function &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read&lt;/code&gt; will convert a string into a float.&lt;/p&gt;

&lt;h3 id=&quot;writing-the-output-file&quot;&gt;Writing the Output File&lt;/h3&gt;
&lt;p&gt;The function &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;writeFile&lt;/code&gt; will write some data into a file:&lt;/p&gt;

&lt;div class=&quot;language-haskell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;writeFile&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;test.txt&quot;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;hello&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This is not a pure function and we will see it again later.&lt;/p&gt;

&lt;h3 id=&quot;all-in-one-function&quot;&gt;All in One Function&lt;/h3&gt;
&lt;p&gt;The pure function portion of the exercise will read as the following:&lt;/p&gt;

&lt;div class=&quot;language-haskell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;report&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;file&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 
	&lt;span class=&quot;kr&quot;&gt;let&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;parsed&lt;/span&gt;		&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;map&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;words&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lines&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;file&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;students&lt;/span&gt;	&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;map&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parsed&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;averages&lt;/span&gt;	&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;map&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;average&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parsed&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;zipped&lt;/span&gt;		&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zipWith&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;report_line&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;students&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;averages&lt;/span&gt;
	&lt;span class=&quot;kr&quot;&gt;in&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;unlines&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zipped&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>Ben Weston</name><email>b.weston60@gmail.com</email></author><category term="COMP105" /><category term="Lectures" /><category term="COMP105" /><category term="Lectures" /><summary type="html">Marks to Report Example This lecture covers a mini assignment example about converting a csv file containing students marks into a report containing the students averages. These are presented in the following format: aaa 70 65 67 60 bbb 55 60 55 65 ccc 40 40 40 40 ddd 80 60 75 60 ccc 0 0 0 100 And should be transformed to be: aaa 65.5 bbb 58.75 ccc 40.0 ddd 68.75 ccc 25.0 See the slides for the full examples. Reading files in Haskell We can read a file using readFile: This is an IO function. We will study this in more detail later on. &amp;gt; readfile &quot;marks.csv&quot; &amp;gt; &quot;aaa 70 65 67 60\nbbb 55 60 55... The \n character is the newline character. lines The lines function takes a string containing multiple lines into a list of strings. The complement to this function is the function unlines. This will do the opposite. Parsing the File Using the functions words and lines we can put the file into a list of lists of strings, in order to process the file. Getting the Averages The function read will convert a string into a float. Writing the Output File The function writeFile will write some data into a file: &amp;gt; writeFile &quot;test.txt&quot; &quot;hello&quot; This is not a pure function and we will see it again later. All in One Function The pure function portion of the exercise will read as the following: report file = let parsed = map words . lines $ file students = map name parsed averages = map average parsed zipped = zipWith report_line students averages in unlines zipped</summary></entry><entry><title type="html">COMP105 - Lecture 18-2</title><link href="http://localhost:4000/UoL/comp105/lectures/2020/11/19/2.html" rel="alternate" type="text/html" title="COMP105 - Lecture 18-2" /><published>2020-11-19T00:00:00+00:00</published><updated>2020-11-19T00:00:00+00:00</updated><id>http://localhost:4000/UoL/comp105/lectures/2020/11/19/2</id><content type="html" xml:base="http://localhost:4000/UoL/comp105/lectures/2020/11/19/2.html">&lt;h2 id=&quot;first-past-the-post-example&quot;&gt;First Past the Post Example&lt;/h2&gt;
&lt;p&gt;This example covers a first past the post election. This means whoever gets the most votes wins. We are aiming to make a function that performs this task:&lt;/p&gt;

&lt;div class=&quot;language-haskell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;winner&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;red&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;blue&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;red&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;red&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;green&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;red&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;getting-the-candidates&quot;&gt;Getting the Candidates&lt;/h3&gt;
&lt;p&gt;First we need to figure out who the candidates are:&lt;/p&gt;

&lt;div class=&quot;language-haskell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;uniq&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;[]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;uniq&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uniq&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xs&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This function will remove duplicates from a list of strings. For every new element found the filter will remove all further occurrences from the rest of the list before recursing on the list.&lt;/p&gt;

&lt;h3 id=&quot;counting-the-votes&quot;&gt;Counting the Votes&lt;/h3&gt;
&lt;p&gt;This function counts the number of votes for a particular  candidate:&lt;/p&gt;

&lt;div class=&quot;language-haskell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;count&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;length&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;vote-totals&quot;&gt;Vote Totals&lt;/h3&gt;
&lt;p&gt;This function will count all the votes for each candidate and put the number of votes and then the candidate in a list of tuples.&lt;/p&gt;

&lt;div class=&quot;language-haskell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;total&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;votes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 
	&lt;span class=&quot;kr&quot;&gt;let&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;candidates&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uniq&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;votes&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;\&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;votes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
	&lt;span class=&quot;kr&quot;&gt;in&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;candidates&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;comparing-candidates&quot;&gt;Comparing Candidates&lt;/h3&gt;
&lt;p&gt;Tuples are compared lexicographically. This means that each element is compared in turn to find which satisfies the function.&lt;/p&gt;

&lt;div class=&quot;language-haskell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;red&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;blue&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;red&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This means that if two candidates have the same number then the string is compared.&lt;/p&gt;

&lt;h4 id=&quot;maximum&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;maximum&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;The function &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;maximum&lt;/code&gt; takes a list and returns the largest item in the list:&lt;/p&gt;

&lt;div class=&quot;language-haskell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maximum&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;red&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;blue&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;green&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;green&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;finding-the-winner&quot;&gt;Finding the Winner&lt;/h3&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;snd&lt;/code&gt; returns the second value in a tuple:&lt;/p&gt;

&lt;div class=&quot;language-haskell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;winner&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;votes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;snd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maximum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;totals&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;votes&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Applying this satisfies the requirement:&lt;/p&gt;

&lt;div class=&quot;language-haskell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;winner&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;red&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;blue&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;red&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;red&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;green&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;red&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;alternative-vote-example&quot;&gt;Alternative Vote Example&lt;/h2&gt;
&lt;p&gt;In the alternative vote system, voters rank the candidates:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;In each round, the candidate with the least number of first preference votes is eliminated.&lt;/li&gt;
  &lt;li&gt;The winner is the last candidate left once all other have been eliminated.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-haskell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;kr&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;votes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;red&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;blue&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;green&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
				&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;blue&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;green&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
				&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;green&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;red&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
				&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;blue&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;red&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
				&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;red&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;av_winner&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;votes&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;red&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;You don’t need many preferences and each list is a single person’s preferences.&lt;/p&gt;

&lt;p class=&quot;info&quot;&gt;See the &lt;a href=&quot;COMP105201119-2.pdf&quot;&gt;slides&lt;/a&gt; for full examples.&lt;/p&gt;

&lt;h3 id=&quot;ranking-the-candidates&quot;&gt;Ranking the Candidates&lt;/h3&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sort&lt;/code&gt; sorts all of the items in a list and orders them from smallest to biggest.&lt;/p&gt;

&lt;h3 id=&quot;getting-the-first-choice-votes&quot;&gt;Getting the First Choice Votes&lt;/h3&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;head&lt;/code&gt; doesn’t accept empty lists as input. This should be taken into account when removing items from lists unevenly.&lt;/p&gt;

&lt;h3 id=&quot;final-function&quot;&gt;Final Function&lt;/h3&gt;
&lt;p&gt;All of the components give this function:&lt;/p&gt;

&lt;div class=&quot;language-haskell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;av_winner&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;votes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;
	&lt;span class=&quot;kr&quot;&gt;let&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;ranked&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rank_candidates&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;votes&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;head&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ranked&lt;/span&gt;
	&lt;span class=&quot;kr&quot;&gt;in&lt;/span&gt;
		&lt;span class=&quot;kr&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;length&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ranked&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
		&lt;span class=&quot;kr&quot;&gt;then&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;first&lt;/span&gt;
		&lt;span class=&quot;kr&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;av_winner&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;remove_cand&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;first&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;votes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>Ben Weston</name><email>b.weston60@gmail.com</email></author><category term="COMP105" /><category term="Lectures" /><category term="COMP105" /><category term="Lectures" /><summary type="html">First Past the Post Example This example covers a first past the post election. This means whoever gets the most votes wins. We are aiming to make a function that performs this task: &amp;gt; winner [&quot;red&quot;, &quot;blue&quot;, &quot;red&quot;, &quot;red&quot;, &quot;green&quot;] &amp;gt; &quot;red&quot; Getting the Candidates First we need to figure out who the candidates are: uniq [] = [] uniq (x:xs) = x : uniq (filter (/=x) xs ) This function will remove duplicates from a list of strings. For every new element found the filter will remove all further occurrences from the rest of the list before recursing on the list. Counting the Votes This function counts the number of votes for a particular candidate: count x list = length (filter (==x) list) Vote Totals This function will count all the votes for each candidate and put the number of votes and then the candidate in a list of tuples. total votes = let candidates = uniq votes f = (\ c -&amp;gt; (count c votes, c)) in map f candidates Comparing Candidates Tuples are compared lexicographically. This means that each element is compared in turn to find which satisfies the function. &amp;gt; max (3, &quot;red&quot;) (2, &quot;blue&quot;) &amp;gt; (3,&quot;red&quot;) This means that if two candidates have the same number then the string is compared. maximum The function maximum takes a list and returns the largest item in the list: &amp;gt; maximum [(3, &quot;red&quot;), (2, &quot;blue&quot;), (4, &quot;green&quot;) &amp;gt; (4, &quot;green&quot;) Finding the Winner snd returns the second value in a tuple: winner votes = snd . maximum . totals $ votes Applying this satisfies the requirement: &amp;gt; winner [&quot;red&quot;, &quot;blue&quot;, &quot;red&quot;, &quot;red&quot;, &quot;green&quot;] &amp;gt; &quot;red&quot; Alternative Vote Example In the alternative vote system, voters rank the candidates: In each round, the candidate with the least number of first preference votes is eliminated. The winner is the last candidate left once all other have been eliminated. &amp;gt; let votes = [[&quot;red&quot;, &quot;blue&quot;, &quot;green&quot;], [&quot;blue&quot;, &quot;green&quot;], [&quot;green&quot;, &quot;red&quot;], [&quot;blue&quot;, &quot;red&quot;], [&quot;red&quot;]] &amp;gt; av_winner votes &amp;gt; &quot;red&quot; You don’t need many preferences and each list is a single person’s preferences. See the slides for full examples. Ranking the Candidates sort sorts all of the items in a list and orders them from smallest to biggest. Getting the First Choice Votes head doesn’t accept empty lists as input. This should be taken into account when removing items from lists unevenly. Final Function All of the components give this function: av_winner votes = let ranked = rank_candidates votes first = head ranked in if length ranked == 1 then first else av_winner (remove_cand first votes)</summary></entry><entry><title type="html">COMP111 - Conditional Probability</title><link href="http://localhost:4000/UoL/comp111/lectures/2020/11/19/1.html" rel="alternate" type="text/html" title="COMP111 - Conditional Probability" /><published>2020-11-19T00:00:00+00:00</published><updated>2020-11-19T00:00:00+00:00</updated><id>http://localhost:4000/UoL/comp111/lectures/2020/11/19/1</id><content type="html" xml:base="http://localhost:4000/UoL/comp111/lectures/2020/11/19/1.html">&lt;p&gt;Often we are interested in just part of the sample space. Conditional probability gives us a means of handling this situation.&lt;/p&gt;

&lt;h2 id=&quot;example&quot;&gt;Example&lt;/h2&gt;
&lt;p&gt;Consider a family chosen at random from a set of families having two children (but not having twins). What is the probability that both children are boys?&lt;/p&gt;

&lt;p&gt;A suitable sample space $S={BB,GB,BG,GG}$.&lt;/p&gt;

&lt;p&gt;It is reasonable to assume that $P(x)=\frac{1}{4}$ for all $x\in S$.&lt;/p&gt;

&lt;p&gt;Thus $P(BB)=\frac{1}{4}$.&lt;/p&gt;

&lt;p&gt;Now you learn that the families were selected from those who have one child at a boys’ school. Does this change probabilities.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;The new sample space $S’={BB,GB,BG}$ and we re now looking for $P(BB&lt;/td&gt;
      &lt;td&gt;\text{at least one boy})+P(BB&lt;/td&gt;
      &lt;td&gt;S’)$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The vertical line is read &lt;strong&gt;given that&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;normalisation&quot;&gt;Normalisation&lt;/h3&gt;
&lt;p&gt;$S’$ is a subset of $S$, so every outcome $x$ in $S’$ is also in $S$. It probability $P(x)\in S$ we can determine.&lt;/p&gt;

&lt;p&gt;However, if we just take the sum of these probabilities, they will sum to less than 1.&lt;/p&gt;

&lt;p&gt;We therefore &lt;strong&gt;normalise&lt;/strong&gt; by dividing the probability $P(x)$ of the outcome $x$ in $S$ by the probability $P(S’)$ of $S’$ in $S$:&lt;/p&gt;

\[P(BB|\text{at least one boy})=P(BB|S')=\frac{P(BB)}{P(S')}=\frac{\frac{1}{4}}{\frac{3}{4}}=\frac{1}{3}\]

&lt;h2 id=&quot;conditioning&quot;&gt;Conditioning&lt;/h2&gt;
&lt;p&gt;Assume now that evens $A$ and $B$ are given.&lt;/p&gt;

&lt;p&gt;Assume we know that $B$ happens. So we want to condition on $B$. Thus, we want to know:&lt;/p&gt;

\[P(A|B)\]

&lt;p&gt;This is the probability that $A$ occurs given that $B$ is know to occur.&lt;/p&gt;

&lt;p&gt;So we want to know the probability $P(A\cap B)$. (as we know that $B$ occurs) after the conditioning on $B$.&lt;/p&gt;

&lt;p&gt;We cant take $P(A\cap B)$ itself but have to normalise by dividing by the probability of the new sample space $P(B)$:&lt;/p&gt;

\[P(A|B)=\frac{P(A\cap B)}{P(B)}\]

&lt;h3 id=&quot;formalised&quot;&gt;Formalised&lt;/h3&gt;
&lt;p&gt;Let $A$ and $B$ be events, with $P(B)&amp;gt;0.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;The conditional probability $P(A&lt;/td&gt;
      &lt;td&gt;B)$ of $A$ given $B$ is given by:&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

\[P(A|B)=\frac{P(A\cap B)}{P(B)}\]

&lt;p class=&quot;info&quot;&gt;View &lt;a href=&quot;COMP111201119.pdf&quot;&gt;slide 27&lt;/a&gt; for additional example.&lt;/p&gt;

&lt;h2 id=&quot;multiplication-rule&quot;&gt;Multiplication Rule&lt;/h2&gt;
&lt;p&gt;We can rewrite the previous equation like so:&lt;/p&gt;

\[P(A\cap B)=P(A|B)P(B)\]

&lt;p&gt;Or like:&lt;/p&gt;

\[P(A\cap B)=P(B|A)P(A)\]

&lt;p&gt;This rule can also be extended to more events:&lt;/p&gt;

\[P(A\cap B\cap C)=P(C|B\cap A)P(A\cap B)=P(C|A\cap B)P(B|A)P(A)\]

&lt;h3 id=&quot;example-1&quot;&gt;Example&lt;/h3&gt;
&lt;p&gt;Consider a family chosen at random from a set of families with just one pair of twins. What is the probability that both twins are boys?&lt;/p&gt;

&lt;p&gt;Twins  are either identical $I$ or fraternal $F$. We know that a third of human twins are identical:&lt;/p&gt;

\[P(I)=\frac{1}{3},P(F)=\frac{2}{3}\]

&lt;p&gt;and&lt;/p&gt;

\[P(BB)=P(I\cap BB) + P(F\cap BB)\]

&lt;p&gt;By the multiplication rule:&lt;/p&gt;

\[P(I\cap BB)= P(BB|I)P(I),\ P(F\cap BB) = P(BB|F)P(F)\]

&lt;p&gt;The probability of being a girl of boy for fraternal twins will be the same as for any other two-child family. For the identical twins, the outcomes $BG$ and $GB$ are no longer possible thus:&lt;/p&gt;

\[P(BB|I)=\frac{1}{2},\ P(BB|F)=\frac{1}{4}\]

&lt;p&gt;From this we obtain:&lt;/p&gt;

&lt;p&gt;$P(BB)=P(I\cap BB) + P(F\cap BB)$&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$=P(BB&lt;/td&gt;
      &lt;td&gt;I)P(I)+ P(BB&lt;/td&gt;
      &lt;td&gt;F)P(F)$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;$=\frac{1}{2}\times\frac{1}{3}+\frac{1}{4}\times\frac{2}{3}$&lt;/p&gt;

&lt;p&gt;$=\frac{1}{3}$&lt;/p&gt;</content><author><name>Ben Weston</name><email>b.weston60@gmail.com</email></author><category term="COMP111" /><category term="Lectures" /><category term="COMP111" /><category term="Lectures" /><summary type="html">Often we are interested in just part of the sample space. Conditional probability gives us a means of handling this situation. Example Consider a family chosen at random from a set of families having two children (but not having twins). What is the probability that both children are boys? A suitable sample space $S={BB,GB,BG,GG}$. It is reasonable to assume that $P(x)=\frac{1}{4}$ for all $x\in S$. Thus $P(BB)=\frac{1}{4}$. Now you learn that the families were selected from those who have one child at a boys’ school. Does this change probabilities. The new sample space $S’={BB,GB,BG}$ and we re now looking for $P(BB \text{at least one boy})+P(BB S’)$ The vertical line is read given that. Normalisation $S’$ is a subset of $S$, so every outcome $x$ in $S’$ is also in $S$. It probability $P(x)\in S$ we can determine. However, if we just take the sum of these probabilities, they will sum to less than 1. We therefore normalise by dividing the probability $P(x)$ of the outcome $x$ in $S$ by the probability $P(S’)$ of $S’$ in $S$: \[P(BB|\text{at least one boy})=P(BB|S')=\frac{P(BB)}{P(S')}=\frac{\frac{1}{4}}{\frac{3}{4}}=\frac{1}{3}\] Conditioning Assume now that evens $A$ and $B$ are given. Assume we know that $B$ happens. So we want to condition on $B$. Thus, we want to know: \[P(A|B)\] This is the probability that $A$ occurs given that $B$ is know to occur. So we want to know the probability $P(A\cap B)$. (as we know that $B$ occurs) after the conditioning on $B$. We cant take $P(A\cap B)$ itself but have to normalise by dividing by the probability of the new sample space $P(B)$: \[P(A|B)=\frac{P(A\cap B)}{P(B)}\] Formalised Let $A$ and $B$ be events, with $P(B)&amp;gt;0. The conditional probability $P(A B)$ of $A$ given $B$ is given by: \[P(A|B)=\frac{P(A\cap B)}{P(B)}\] View slide 27 for additional example. Multiplication Rule We can rewrite the previous equation like so: \[P(A\cap B)=P(A|B)P(B)\] Or like: \[P(A\cap B)=P(B|A)P(A)\] This rule can also be extended to more events: \[P(A\cap B\cap C)=P(C|B\cap A)P(A\cap B)=P(C|A\cap B)P(B|A)P(A)\] Example Consider a family chosen at random from a set of families with just one pair of twins. What is the probability that both twins are boys? Twins are either identical $I$ or fraternal $F$. We know that a third of human twins are identical: \[P(I)=\frac{1}{3},P(F)=\frac{2}{3}\] and \[P(BB)=P(I\cap BB) + P(F\cap BB)\] By the multiplication rule: \[P(I\cap BB)= P(BB|I)P(I),\ P(F\cap BB) = P(BB|F)P(F)\] The probability of being a girl of boy for fraternal twins will be the same as for any other two-child family. For the identical twins, the outcomes $BG$ and $GB$ are no longer possible thus: \[P(BB|I)=\frac{1}{2},\ P(BB|F)=\frac{1}{4}\] From this we obtain: $P(BB)=P(I\cap BB) + P(F\cap BB)$ $=P(BB I)P(I)+ P(BB F)P(F)$ $=\frac{1}{2}\times\frac{1}{3}+\frac{1}{4}\times\frac{2}{3}$ $=\frac{1}{3}$</summary></entry><entry><title type="html">COMP111 - Independence</title><link href="http://localhost:4000/UoL/comp111/lectures/2020/11/19/2.html" rel="alternate" type="text/html" title="COMP111 - Independence" /><published>2020-11-19T00:00:00+00:00</published><updated>2020-11-19T00:00:00+00:00</updated><id>http://localhost:4000/UoL/comp111/lectures/2020/11/19/2</id><content type="html" xml:base="http://localhost:4000/UoL/comp111/lectures/2020/11/19/2.html">&lt;p&gt;In everyday language we refer to events that have nothing to do with each other as being independent.&lt;/p&gt;

&lt;h2 id=&quot;definition&quot;&gt;Definition&lt;/h2&gt;
&lt;p&gt;Events $A$ and $B$ are independent if:&lt;/p&gt;

\[P(A\cap B)=P(A)\times P(B)\]

&lt;p&gt;If $P(A)\neq 0$ and $P(B)\neq 0$, then the following are equivalent:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$A$ and $B$ are independent.&lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;$P(B)=P(B&lt;/td&gt;
          &lt;td&gt;A)$&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;$P(A)=P(A&lt;/td&gt;
          &lt;td&gt;B)$&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;info&quot;&gt;See &lt;a href=&quot;COMP111201119.pdf&quot;&gt;slides 31&lt;/a&gt; for additional examples. This covers proving independence using the definition above.&lt;/p&gt;

&lt;h2 id=&quot;independence-for-more-than-two-events&quot;&gt;Independence for More Than Two Events&lt;/h2&gt;
&lt;p&gt;For a finite set of events there are two different types of independence:&lt;/p&gt;

&lt;h3 id=&quot;pairwise-independence&quot;&gt;Pairwise Independence&lt;/h3&gt;
&lt;p&gt;$A_1,\ldots,A_n$ are pairwise independent if every pair of events is independent: for all distinct $k,m$&lt;/p&gt;

\[P(A_m\cap A_k)=P(A_m)P(A_k)\]

&lt;h3 id=&quot;mutual-independence&quot;&gt;Mutual Independence&lt;/h3&gt;
&lt;p&gt;$A_1,\ldots,A_n$ are mutually independent if every event is independent of any intersection of the events: for all distinct $k,m$&lt;/p&gt;

\[P(A_{k1})\times\ldots\times P(A_{k_m})=P(A_{k_1}\cap\ldots\cap A_{k_m})\]

&lt;p&gt;Pairwise independence doesn’t imply pairwise independence. Generally, if it isn’t stated, then we are talking about &lt;strong&gt;mutual independence&lt;/strong&gt;.&lt;/p&gt;

&lt;p class=&quot;info&quot;&gt;To see the proof and example of why pairwise independence does not imply mutual independence see &lt;a href=&quot;COMP111201119.pdf&quot;&gt;slide 37 onward&lt;/a&gt;. This example also shows examples of probability set notation.&lt;/p&gt;</content><author><name>Ben Weston</name><email>b.weston60@gmail.com</email></author><category term="COMP111" /><category term="Lectures" /><category term="COMP111" /><category term="Lectures" /><summary type="html">In everyday language we refer to events that have nothing to do with each other as being independent. Definition Events $A$ and $B$ are independent if: \[P(A\cap B)=P(A)\times P(B)\] If $P(A)\neq 0$ and $P(B)\neq 0$, then the following are equivalent: $A$ and $B$ are independent. $P(B)=P(B A)$ $P(A)=P(A B)$ See slides 31 for additional examples. This covers proving independence using the definition above. Independence for More Than Two Events For a finite set of events there are two different types of independence: Pairwise Independence $A_1,\ldots,A_n$ are pairwise independent if every pair of events is independent: for all distinct $k,m$ \[P(A_m\cap A_k)=P(A_m)P(A_k)\] Mutual Independence $A_1,\ldots,A_n$ are mutually independent if every event is independent of any intersection of the events: for all distinct $k,m$ \[P(A_{k1})\times\ldots\times P(A_{k_m})=P(A_{k_1}\cap\ldots\cap A_{k_m})\] Pairwise independence doesn’t imply pairwise independence. Generally, if it isn’t stated, then we are talking about mutual independence. To see the proof and example of why pairwise independence does not imply mutual independence see slide 37 onward. This example also shows examples of probability set notation.</summary></entry><entry><title type="html">COMP111 - Bayes’ Theorem</title><link href="http://localhost:4000/UoL/comp111/lectures/2020/11/19/3.html" rel="alternate" type="text/html" title="COMP111 - Bayes’ Theorem" /><published>2020-11-19T00:00:00+00:00</published><updated>2020-11-19T00:00:00+00:00</updated><id>http://localhost:4000/UoL/comp111/lectures/2020/11/19/3</id><content type="html" xml:base="http://localhost:4000/UoL/comp111/lectures/2020/11/19/3.html">&lt;h2 id=&quot;first-form&quot;&gt;First Form&lt;/h2&gt;
&lt;p&gt;If $P(A)&amp;gt;0$, then:&lt;/p&gt;

\[P(B|A)=\frac{P(A|B)\times P(B)}{P(A)}\]

&lt;h3 id=&quot;proof&quot;&gt;Proof&lt;/h3&gt;
&lt;p&gt;We have:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;$P(A\cap B)=P(A&lt;/td&gt;
          &lt;td&gt;B)\times P(B)$&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;$P(A\cap B)=P(B&lt;/td&gt;
          &lt;td&gt;A)\times P(A)$&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Thus:&lt;/p&gt;

\[P(A|B)\times P(B)=P(B|A)\times P(A)\]

&lt;p&gt;By dividing by $P(A)$ we get:&lt;/p&gt;

\[P(B|A)=\frac{P(A|B)\times P(B)}{P(A)}\]

&lt;h3 id=&quot;application---diagnosis&quot;&gt;Application - Diagnosis&lt;/h3&gt;
&lt;p&gt;Assume a patient walks into a doctor’s office complaining of a stiff neck. The doctor knows:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Meningitis may cause a patient to have a stiff neck 50% of the time.
    &lt;ul&gt;
      &lt;li&gt;Causal knowledge.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;The probability of having meningitis is $\frac{1}{50000}$&lt;/li&gt;
  &lt;li&gt;The probability of having a stiff neck is $\frac{1}{20}$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;What is the probability that the patient has meningitis?&lt;/p&gt;

&lt;p&gt;Let $A$ be the event that the patient has a stiff neck and $B$ the event that they have meningitis:&lt;/p&gt;

\[P(B|A)=\frac{P(A|B)\times P(B)}{P(A)}=\frac{\frac{1}{2}\times \frac{1}{50000}}{\frac{1}{20}}=\frac{1}{5000}\]

&lt;ul&gt;
  &lt;li&gt;We can interpret the fact that the patient has a stiff neck as a new &lt;strong&gt;observation&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;Given this observation, we want to &lt;strong&gt;classify&lt;/strong&gt; that patient as either having meningitis or not having meningitis.&lt;/li&gt;
  &lt;li&gt;We have &lt;strong&gt;prior&lt;/strong&gt; knowledge about the &lt;strong&gt;unconditional&lt;/strong&gt; probability of having a stiff neck.&lt;/li&gt;
  &lt;li&gt;We have &lt;strong&gt;causal&lt;/strong&gt; knowledge about the number of times in which meningitis causes a stiff neck.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;We can then compute the diagnostic probabilities using:&lt;/p&gt;

\[P(B|A)=\frac{P(A|B)\times P(B)}{P(A)}\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;alternative-form&quot;&gt;Alternative Form&lt;/h2&gt;
&lt;p&gt;You may not have the prior probability for $A$ (the observation). In this case you can use other things that you might know in this alternative form.&lt;/p&gt;

&lt;p&gt;If $P(A)&amp;gt;0$, then:&lt;/p&gt;

\[P(B|A)=\frac{P(A|B)\times P(B)}{P(A|B)\times P(B)+P(A|\neg B)\times P(\neg B)}\]

&lt;h3 id=&quot;proof-1&quot;&gt;Proof&lt;/h3&gt;
&lt;p&gt;It suffices to show:&lt;/p&gt;

\[P(A)=P(A|B)\times P(B)+P(A|\neg B) \times P(\neg B)\]

&lt;p&gt;But this follows from:&lt;/p&gt;

&lt;p&gt;$P(A)=P((A\cap B)\cup (A\cap \neg B))$&lt;/p&gt;

&lt;p&gt;$=P(A\cap B)+P(A\cap\neg B)$&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$=P(A&lt;/td&gt;
      &lt;td&gt;B)\times P(B)+P(A&lt;/td&gt;
      &lt;td&gt;\neg B)\times P(\neg B)$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;application---diagnosis-1&quot;&gt;Application - Diagnosis&lt;/h3&gt;
&lt;p&gt;Assume a drug test is:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Positive for users 99% of the time.&lt;/li&gt;
  &lt;li&gt;Negative for non-users 99% of the time.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Assume that 0.5% take the drug.&lt;/p&gt;

&lt;p&gt;What is the probability that a person whose test is positive (event $A$) takes the drug (event $B$)?&lt;/p&gt;

&lt;p&gt;We have:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;$P(A&lt;/td&gt;
          &lt;td&gt;B)=\frac{99}{100}$&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;$P(\neg A&lt;/td&gt;
          &lt;td&gt;\neg B)=\frac{99}{100}$&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;$P(B)=\frac{1}{200}$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Thus:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;$P(A&lt;/td&gt;
          &lt;td&gt;\neg B) =\frac{1}{100}$&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;$P(\neg B) =\frac{199}{200}$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Thus:&lt;/p&gt;

\[P(B|A)=\frac{P(A|B)\times P(B)}{P(A|B)\times P(B)+P(A|\neg B)\times P(\neg B)}=\frac{99}{298}\approx0.33\]

&lt;p&gt;Due to the low value it means that it is hard to take an action based on the test. This is as a result of the low value of the people who take the drug. This results in many false positives for those that don’t.&lt;/p&gt;</content><author><name>Ben Weston</name><email>b.weston60@gmail.com</email></author><category term="COMP111" /><category term="Lectures" /><category term="COMP111" /><category term="Lectures" /><summary type="html">First Form If $P(A)&amp;gt;0$, then: \[P(B|A)=\frac{P(A|B)\times P(B)}{P(A)}\] Proof We have: $P(A\cap B)=P(A B)\times P(B)$ $P(A\cap B)=P(B A)\times P(A)$ Thus: \[P(A|B)\times P(B)=P(B|A)\times P(A)\] By dividing by $P(A)$ we get: \[P(B|A)=\frac{P(A|B)\times P(B)}{P(A)}\] Application - Diagnosis Assume a patient walks into a doctor’s office complaining of a stiff neck. The doctor knows: Meningitis may cause a patient to have a stiff neck 50% of the time. Causal knowledge. The probability of having meningitis is $\frac{1}{50000}$ The probability of having a stiff neck is $\frac{1}{20}$ What is the probability that the patient has meningitis? Let $A$ be the event that the patient has a stiff neck and $B$ the event that they have meningitis: \[P(B|A)=\frac{P(A|B)\times P(B)}{P(A)}=\frac{\frac{1}{2}\times \frac{1}{50000}}{\frac{1}{20}}=\frac{1}{5000}\] We can interpret the fact that the patient has a stiff neck as a new observation. Given this observation, we want to classify that patient as either having meningitis or not having meningitis. We have prior knowledge about the unconditional probability of having a stiff neck. We have causal knowledge about the number of times in which meningitis causes a stiff neck. We can then compute the diagnostic probabilities using: \[P(B|A)=\frac{P(A|B)\times P(B)}{P(A)}\] Alternative Form You may not have the prior probability for $A$ (the observation). In this case you can use other things that you might know in this alternative form. If $P(A)&amp;gt;0$, then: \[P(B|A)=\frac{P(A|B)\times P(B)}{P(A|B)\times P(B)+P(A|\neg B)\times P(\neg B)}\] Proof It suffices to show: \[P(A)=P(A|B)\times P(B)+P(A|\neg B) \times P(\neg B)\] But this follows from: $P(A)=P((A\cap B)\cup (A\cap \neg B))$ $=P(A\cap B)+P(A\cap\neg B)$ $=P(A B)\times P(B)+P(A \neg B)\times P(\neg B)$ Application - Diagnosis Assume a drug test is: Positive for users 99% of the time. Negative for non-users 99% of the time. Assume that 0.5% take the drug. What is the probability that a person whose test is positive (event $A$) takes the drug (event $B$)? We have: $P(A B)=\frac{99}{100}$ $P(\neg A \neg B)=\frac{99}{100}$ $P(B)=\frac{1}{200}$ Thus: $P(A \neg B) =\frac{1}{100}$ $P(\neg B) =\frac{199}{200}$ Thus: \[P(B|A)=\frac{P(A|B)\times P(B)}{P(A|B)\times P(B)+P(A|\neg B)\times P(\neg B)}=\frac{99}{298}\approx0.33\] Due to the low value it means that it is hard to take an action based on the test. This is as a result of the low value of the people who take the drug. This results in many false positives for those that don’t.</summary></entry><entry><title type="html">COMP107 - Basic Definitions in the ER Model</title><link href="http://localhost:4000/UoL/comp107/lectures/2020/11/18/1.html" rel="alternate" type="text/html" title="COMP107 - Basic Definitions in the ER Model" /><published>2020-11-18T00:00:00+00:00</published><updated>2020-11-18T00:00:00+00:00</updated><id>http://localhost:4000/UoL/comp107/lectures/2020/11/18/1</id><content type="html" xml:base="http://localhost:4000/UoL/comp107/lectures/2020/11/18/1.html">&lt;p&gt;The entity relationship model is used to express the conceptual schema of a database. It was originally proposed in 1976 as a means to unify the network and relational DB models.&lt;/p&gt;

&lt;p&gt;Many theoretical extensions and practical applications have been developed including the &lt;strong&gt;Enhanced Entity Relationship (EER)&lt;/strong&gt; model.&lt;/p&gt;

&lt;p&gt;It is simple enough to learn and understand the basic concepts and powerful enough to be used in the development of complex applications.&lt;/p&gt;

&lt;p&gt;Conceptual designs using the ER model are called &lt;strong&gt;ER Schemas&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;er-model-components&quot;&gt;ER Model Components&lt;/h2&gt;
&lt;p&gt;The ER model describes data in terms of three primitive notions.&lt;/p&gt;

&lt;h3 id=&quot;entities&quot;&gt;Entities&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;An entity is a thing, which can be distinctly identified.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;attributes&quot;&gt;Attributes&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;A property of an entity.&lt;/li&gt;
  &lt;li&gt;They are common properties that are shared by all instances of the entity type.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;complexity-of-attributes&quot;&gt;Complexity of Attributes&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Complex attributes have structure.
    &lt;ul&gt;
      &lt;li&gt;Dates&lt;/li&gt;
      &lt;li&gt;Addresses&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Simple attributes only have one component.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;cardinality&quot;&gt;Cardinality&lt;/h4&gt;
&lt;p&gt;Some attributes may have more than one value. If this is the case then you can say that a particular value has a cardinality $&amp;gt;0$.&lt;/p&gt;

&lt;h4 id=&quot;primitiveness&quot;&gt;Primitiveness&lt;/h4&gt;
&lt;p&gt;A primitive attribute is any attribute which will be stored as data in the system.&lt;/p&gt;

&lt;p&gt;A non-primitive, or derived attribute, can be calculated from other attributes.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;In some cases it is important that both attributes are indicated on the model
    &lt;ul&gt;
      &lt;li&gt;We should indicate which ones are redundant so that they can be derived.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;relationships&quot;&gt;Relationships&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;An association among entities.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;degree-of-relationships&quot;&gt;Degree of Relationships&lt;/h4&gt;
&lt;p&gt;A relationship has a degree that is the number of participating entity types:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Binary relationship (degree two).
    &lt;ul&gt;
      &lt;li&gt;A &lt;strong&gt;person&lt;/strong&gt; owns a &lt;strong&gt;car&lt;/strong&gt;.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Ternary relationships (degree three).
    &lt;ul&gt;
      &lt;li&gt;A &lt;strong&gt;lecturer&lt;/strong&gt; teaches a &lt;strong&gt;course&lt;/strong&gt; to a &lt;strong&gt;student&lt;/strong&gt;.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;attributes-of-relationships&quot;&gt;Attributes of Relationships&lt;/h4&gt;
&lt;p&gt;Relationships can have attributes in the case that the attribute is not of an entity but when it is related to the relationship.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;In the relationship type, “person owns a car” the attribute &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;date of purchase&lt;/code&gt; is not an attribute of a person and is not an attribute of the car, it is an attribute of the ownership.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;structural-constrains-on-relationships&quot;&gt;Structural Constrains on Relationships&lt;/h4&gt;
&lt;p&gt;Relationship constraints regulate the possible combinations of entities that can participate in a relationship:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;We can constrain the number of entities that can participate.&lt;/li&gt;
  &lt;li&gt;We can put a constraint on whether some entities must participate.&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;relationship-participation&quot;&gt;Relationship Participation&lt;/h5&gt;
&lt;p&gt;A participation constraint specifies whether an entity must be in the given relationship.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A &lt;strong&gt;total participation constraint&lt;/strong&gt;, indicates that each instance of an entity must be in that relationship.
    &lt;ul&gt;
      &lt;li&gt;A programme must belong to a department.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;A &lt;strong&gt;partial participation constraint&lt;/strong&gt; specifies that there may exist an entity which does not participate in the relationship.
    &lt;ul&gt;
      &lt;li&gt;Not all lecturers supervise students.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;cardinality-of-relationships&quot;&gt;Cardinality of Relationships&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;One to One
    &lt;ul&gt;
      &lt;li&gt;One department only has one head.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;One to Many
    &lt;ul&gt;
      &lt;li&gt;Each team can have many players but one player can only play for one team.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Many to Many
    &lt;ul&gt;
      &lt;li&gt;A student can be registered for many courses and a course will have may students.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;er-diagram-basics&quot;&gt;ER Diagram Basics&lt;/h2&gt;
&lt;p&gt;Entity types are represented as boxes:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-mermaid&quot;&gt;graph TD
Lecturer
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Relationship types are represented as diamonds connected with each participating entity type. The relationship must have a name.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-mermaid&quot;&gt;graph TD
a{works_in}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Attributes are shown as ovals connected to the relevant entity or relation type. In addition key attributes are underlined.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The key attribute should only be underlined if it arises naturally. If not there should be a key put in later in implementation.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&quot;language-mermaid&quot;&gt;graph TD
a((Name))
b((&amp;lt;u&amp;gt;Key&amp;lt;/u&amp;gt;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This will come together to form the following diagram:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-mermaid&quot;&gt;graph LR
d[Department] --- a{works_in}
a --- l[Lecturer]
l --- n((Name))
l --- s((&amp;lt;u&amp;gt;Staff Number&amp;lt;/u&amp;gt;))
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;er-diagram-attributes&quot;&gt;ER Diagram Attributes&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;A simple primitive attribute is represented as an oval:&lt;/p&gt;

    &lt;pre&gt;&lt;code class=&quot;language-mermaid&quot;&gt;  graph TD
  d((Date of Birth))
  t((Tax Code))
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Complex attributes can have their own structure made of simple attributes:&lt;/p&gt;

    &lt;pre&gt;&lt;code class=&quot;language-mermaid&quot;&gt;  graph BT
  n((Name))
  n --- f((First Name))
  n --- m((Middle Name))
  n --- l((Last Name))
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;A multi-valued attribute is a double oval:&lt;/p&gt;

    &lt;pre&gt;&lt;code class=&quot;language-mermaid&quot;&gt;  graph TD
  e((&quot;(E-Mail Address)&quot;))
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;A derived attribute is a dotted oval:&lt;/p&gt;

    &lt;pre&gt;&lt;code class=&quot;language-mermaid&quot;&gt;  graph TD
  a((Age))
  style a stroke-dasharray: 2 4
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;er-diagram-relationships&quot;&gt;ER Diagram Relationships&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;The degree of a relationship type is simply the number of entity types it connects.&lt;/li&gt;
  &lt;li&gt;Binary relationships between two entities.&lt;/li&gt;
  &lt;li&gt;Ternary relationships among three entities.&lt;/li&gt;
  &lt;li&gt;If entities participate to several relationships, a &lt;em&gt;role&lt;/em&gt; may be added to some edges for clarity.&lt;/li&gt;
  &lt;li&gt;The cardinality is represented on the connecting lines (an $N$ represents the many side.
    &lt;ul&gt;
      &lt;li&gt;One to many (works_in)&lt;/li&gt;
      &lt;li&gt;Many to many (teaches, advises)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Total participation is represented by a double line. (I have used thick)
    &lt;ul&gt;
      &lt;li&gt;A lecturer must work in a Dept.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Relationships can have attributes.
    &lt;ul&gt;
      &lt;li&gt;A student may have different advisors for different majors.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&quot;language-mermaid&quot;&gt;graph LR
l[Lecturer] ===|N| w{works_in}
w ---|1| d[Department]
l ---|N| t{teaches}
t ---|N| c[Course]
t ---|N| s[Student]
l ---|N, academic advisor| a{advises}
a ---|N| s
m((Major)) --- a
&lt;/code&gt;&lt;/pre&gt;</content><author><name>Ben Weston</name><email>b.weston60@gmail.com</email></author><category term="COMP107" /><category term="Lectures" /><category term="COMP107" /><category term="Lectures" /><summary type="html">The entity relationship model is used to express the conceptual schema of a database. It was originally proposed in 1976 as a means to unify the network and relational DB models. Many theoretical extensions and practical applications have been developed including the Enhanced Entity Relationship (EER) model. It is simple enough to learn and understand the basic concepts and powerful enough to be used in the development of complex applications. Conceptual designs using the ER model are called ER Schemas ER Model Components The ER model describes data in terms of three primitive notions. Entities An entity is a thing, which can be distinctly identified. Attributes A property of an entity. They are common properties that are shared by all instances of the entity type. Complexity of Attributes Complex attributes have structure. Dates Addresses Simple attributes only have one component. Cardinality Some attributes may have more than one value. If this is the case then you can say that a particular value has a cardinality $&amp;gt;0$. Primitiveness A primitive attribute is any attribute which will be stored as data in the system. A non-primitive, or derived attribute, can be calculated from other attributes. In some cases it is important that both attributes are indicated on the model We should indicate which ones are redundant so that they can be derived. Relationships An association among entities. Degree of Relationships A relationship has a degree that is the number of participating entity types: Binary relationship (degree two). A person owns a car. Ternary relationships (degree three). A lecturer teaches a course to a student. Attributes of Relationships Relationships can have attributes in the case that the attribute is not of an entity but when it is related to the relationship. In the relationship type, “person owns a car” the attribute date of purchase is not an attribute of a person and is not an attribute of the car, it is an attribute of the ownership. Structural Constrains on Relationships Relationship constraints regulate the possible combinations of entities that can participate in a relationship: We can constrain the number of entities that can participate. We can put a constraint on whether some entities must participate. Relationship Participation A participation constraint specifies whether an entity must be in the given relationship. A total participation constraint, indicates that each instance of an entity must be in that relationship. A programme must belong to a department. A partial participation constraint specifies that there may exist an entity which does not participate in the relationship. Not all lecturers supervise students. Cardinality of Relationships One to One One department only has one head. One to Many Each team can have many players but one player can only play for one team. Many to Many A student can be registered for many courses and a course will have may students. ER Diagram Basics Entity types are represented as boxes: graph TD Lecturer Relationship types are represented as diamonds connected with each participating entity type. The relationship must have a name. graph TD a{works_in} Attributes are shown as ovals connected to the relevant entity or relation type. In addition key attributes are underlined. The key attribute should only be underlined if it arises naturally. If not there should be a key put in later in implementation. graph TD a((Name)) b((&amp;lt;u&amp;gt;Key&amp;lt;/u&amp;gt;)) This will come together to form the following diagram: graph LR d[Department] --- a{works_in} a --- l[Lecturer] l --- n((Name)) l --- s((&amp;lt;u&amp;gt;Staff Number&amp;lt;/u&amp;gt;)) ER Diagram Attributes A simple primitive attribute is represented as an oval: graph TD d((Date of Birth)) t((Tax Code)) Complex attributes can have their own structure made of simple attributes: graph BT n((Name)) n --- f((First Name)) n --- m((Middle Name)) n --- l((Last Name)) A multi-valued attribute is a double oval: graph TD e((&quot;(E-Mail Address)&quot;)) A derived attribute is a dotted oval: graph TD a((Age)) style a stroke-dasharray: 2 4 ER Diagram Relationships The degree of a relationship type is simply the number of entity types it connects. Binary relationships between two entities. Ternary relationships among three entities. If entities participate to several relationships, a role may be added to some edges for clarity. The cardinality is represented on the connecting lines (an $N$ represents the many side. One to many (works_in) Many to many (teaches, advises) Total participation is represented by a double line. (I have used thick) A lecturer must work in a Dept. Relationships can have attributes. A student may have different advisors for different majors. graph LR l[Lecturer] ===|N| w{works_in} w ---|1| d[Department] l ---|N| t{teaches} t ---|N| c[Course] t ---|N| s[Student] l ---|N, academic advisor| a{advises} a ---|N| s m((Major)) --- a</summary></entry><entry><title type="html">COMP111 - Reasoning Under Uncertainty</title><link href="http://localhost:4000/UoL/comp111/lectures/2020/11/18/1.html" rel="alternate" type="text/html" title="COMP111 - Reasoning Under Uncertainty" /><published>2020-11-18T00:00:00+00:00</published><updated>2020-11-18T00:00:00+00:00</updated><id>http://localhost:4000/UoL/comp111/lectures/2020/11/18/1</id><content type="html" xml:base="http://localhost:4000/UoL/comp111/lectures/2020/11/18/1.html">&lt;p&gt;Logic based knowledge representation and reasoning methods mostly assume that knowledge is certain. Often, this is not the case (or it is impossible to list all assumptions that make it certain):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;When going to the airport by car, how early should I start? 45 minutes should be enough from Liverpool to Manchester Airport, but only under the assumption that there are no accidents, no lane closures, that my car does not break down, and so on.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;A dental patient has a toothache. Does the patient have a cavity? You might say:&lt;/p&gt;

\[\text{Toothache}(x)\rightarrow\text{Cavity}(x)\]

    &lt;p&gt;This is not right as there are many factors that play into this and not just the fact that they have a toothache.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;uncertainty&quot;&gt;Uncertainty&lt;/h2&gt;
&lt;p&gt;Trying to use exact rules to cope with a domain like medical diagnosis or traffic fails for three main reasons:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Laziness
    &lt;ul&gt;
      &lt;li&gt;It is too much work to list an exception-less set of rules.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Theoretical ignorance
    &lt;ul&gt;
      &lt;li&gt;Medical science has, in many cases, no strict laws connecting symptoms with diseases.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Practical ignorance
    &lt;ul&gt;
      &lt;li&gt;Even if we have strict laws, we might be uncertain about a particular patient because not all the necessary tests have been or can be run.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;probability-in-ai&quot;&gt;Probability in AI&lt;/h2&gt;

&lt;p&gt;Probability provides a way of summarising the uncertainty that comes form our laziness and ignorance.&lt;/p&gt;

&lt;p&gt;We might not know for sure what disease a particular patient has, but we believe that there is an 80% chance that a patient with toothache has a cavity. The 80% summarises those cases in which all the factors needed for a cavity to cause a toothache are present and other cases in which the patient has both toothache and cavity but the two are unconnected.&lt;/p&gt;

&lt;p&gt;The missing 20% summarises all the other possible causes we are too lazy or ignorant to find.&lt;/p&gt;

&lt;h2 id=&quot;discrete-probability&quot;&gt;Discrete Probability&lt;/h2&gt;
&lt;p&gt;We represent random experiments using discrete probability spaces $(S,P)$ consisting of:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The sample space $S$ of all elementary events $x\in S$. Members of $S$ are also called outcomes of the experiment.&lt;/li&gt;
  &lt;li&gt;A probability distribution $P$ assigning a real number $P(x)$ to every elementary event $x\in S$ such that:
    &lt;ul&gt;
      &lt;li&gt;For every $x\in S: 0\leq P(x) \leq 1$&lt;/li&gt;
      &lt;li&gt;And $\sum_{x\in S}P(x)=1$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Recall that if $S$ consists of $x_1,\ldots,x_n$, then:&lt;/p&gt;

\[\sum_{x\in S}P(x)=P(x_1)+\ldots+P(x_n)\]

&lt;h3 id=&quot;example---flipping-a-fair-coin&quot;&gt;Example - Flipping a Fair Coin&lt;/h3&gt;
&lt;p&gt;Consider the random experiment of flipping a coin. The then corresponding probability space $(S,P)$ is given by:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$S={H,T}$&lt;/li&gt;
  &lt;li&gt;$P(H)=P(T)=\frac{1}{2}$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Consider the random experiment of flipping a count two times, one after the other. Then the corresponding probability space $(S,P)$ is:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$S={HH,HT,TH,TT}$&lt;/li&gt;
  &lt;li&gt;$P(HH)=P(HT)=P(TH)=P(TT)=\frac{1}{4}$&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;example---rolling-a-fair-die&quot;&gt;Example - Rolling a fair die&lt;/h3&gt;
&lt;p&gt;Consider the random experiment of rolling a die. Then the corresponding probability space $(S, P)$ is given by:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;S = {1, 2, 3, 4, 5, 6};&lt;/li&gt;
  &lt;li&gt;For every $x ∈ S: P(x) = \frac{1}{6}$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Consider the random experiment of rolling a die $n$ times. Then the corresponding probability space $(S, P)$ is given as follows:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$S$ is the set of sequences of length $n$ over the alphabet ${1,\ldots, 6}$
    &lt;ul&gt;
      &lt;li&gt;Sometimes denoted ${1,\ldots, 6}^n$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;$P(x) = \frac{1}{6^n}$ for every elementary event $x$, since $S$ has $6^n$ elements.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;uniform-probability-distributions&quot;&gt;Uniform Probability Distributions&lt;/h2&gt;
&lt;p&gt;A probability distribution is uniform if every outcome is equally likely. For uniform probability distributions, the probability of an outcome $x$ is 1 divided by the number $|S|$ of outcomes in $S$:&lt;/p&gt;

\[P(x)=\frac{1}{|S|}\]</content><author><name>Ben Weston</name><email>b.weston60@gmail.com</email></author><category term="COMP111" /><category term="Lectures" /><category term="COMP111" /><category term="Lectures" /><summary type="html">Logic based knowledge representation and reasoning methods mostly assume that knowledge is certain. Often, this is not the case (or it is impossible to list all assumptions that make it certain): When going to the airport by car, how early should I start? 45 minutes should be enough from Liverpool to Manchester Airport, but only under the assumption that there are no accidents, no lane closures, that my car does not break down, and so on. A dental patient has a toothache. Does the patient have a cavity? You might say: \[\text{Toothache}(x)\rightarrow\text{Cavity}(x)\] This is not right as there are many factors that play into this and not just the fact that they have a toothache. Uncertainty Trying to use exact rules to cope with a domain like medical diagnosis or traffic fails for three main reasons: Laziness It is too much work to list an exception-less set of rules. Theoretical ignorance Medical science has, in many cases, no strict laws connecting symptoms with diseases. Practical ignorance Even if we have strict laws, we might be uncertain about a particular patient because not all the necessary tests have been or can be run. Probability in AI Probability provides a way of summarising the uncertainty that comes form our laziness and ignorance. We might not know for sure what disease a particular patient has, but we believe that there is an 80% chance that a patient with toothache has a cavity. The 80% summarises those cases in which all the factors needed for a cavity to cause a toothache are present and other cases in which the patient has both toothache and cavity but the two are unconnected. The missing 20% summarises all the other possible causes we are too lazy or ignorant to find. Discrete Probability We represent random experiments using discrete probability spaces $(S,P)$ consisting of: The sample space $S$ of all elementary events $x\in S$. Members of $S$ are also called outcomes of the experiment. A probability distribution $P$ assigning a real number $P(x)$ to every elementary event $x\in S$ such that: For every $x\in S: 0\leq P(x) \leq 1$ And $\sum_{x\in S}P(x)=1$ Recall that if $S$ consists of $x_1,\ldots,x_n$, then: \[\sum_{x\in S}P(x)=P(x_1)+\ldots+P(x_n)\] Example - Flipping a Fair Coin Consider the random experiment of flipping a coin. The then corresponding probability space $(S,P)$ is given by: $S={H,T}$ $P(H)=P(T)=\frac{1}{2}$ Consider the random experiment of flipping a count two times, one after the other. Then the corresponding probability space $(S,P)$ is: $S={HH,HT,TH,TT}$ $P(HH)=P(HT)=P(TH)=P(TT)=\frac{1}{4}$ Example - Rolling a fair die Consider the random experiment of rolling a die. Then the corresponding probability space $(S, P)$ is given by: S = {1, 2, 3, 4, 5, 6}; For every $x ∈ S: P(x) = \frac{1}{6}$ Consider the random experiment of rolling a die $n$ times. Then the corresponding probability space $(S, P)$ is given as follows: $S$ is the set of sequences of length $n$ over the alphabet ${1,\ldots, 6}$ Sometimes denoted ${1,\ldots, 6}^n$ $P(x) = \frac{1}{6^n}$ for every elementary event $x$, since $S$ has $6^n$ elements. Uniform Probability Distributions A probability distribution is uniform if every outcome is equally likely. For uniform probability distributions, the probability of an outcome $x$ is 1 divided by the number $|S|$ of outcomes in $S$: \[P(x)=\frac{1}{|S|}\]</summary></entry><entry><title type="html">COMP111 - Events</title><link href="http://localhost:4000/UoL/comp111/lectures/2020/11/18/2.html" rel="alternate" type="text/html" title="COMP111 - Events" /><published>2020-11-18T00:00:00+00:00</published><updated>2020-11-18T00:00:00+00:00</updated><id>http://localhost:4000/UoL/comp111/lectures/2020/11/18/2</id><content type="html" xml:base="http://localhost:4000/UoL/comp111/lectures/2020/11/18/2.html">&lt;p&gt;An event is a subset $E ⊆ S$ of the sample space $S$. The probability of the even $E$ is given by:&lt;/p&gt;

\[P(E)=\sum_{x\in E}P(x)\]

&lt;ul&gt;
  &lt;li&gt;$0 ≤ P(E) ≤ 1$ for every event $E$&lt;/li&gt;
  &lt;li&gt;$P(\emptyset) = 0$ and $P(S) = 1$&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;example---fair-dice&quot;&gt;Example - Fair Dice&lt;/h2&gt;
&lt;p&gt;If I roll a die three times, the event $E$ of rolling at least one 6 is given by:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The set of sequences of length 4 over ${1,\ldots,6}$ containing at least one 6.&lt;/li&gt;
  &lt;li&gt;$P(E)$ is the number of sequences containing at least one 6 divided by $6\times6\times6\times6=216$.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If we roll a fair die, then the event E of rolling an odd number is given by:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The set $E={1,3,5}$&lt;/li&gt;
  &lt;li&gt;$P(E)=P(1)+P(3)+P(5)=\frac{1}{6}+\frac{1}{6}+\frac{1}{6}=\frac{1}{2}$&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;probability-of-composed-events&quot;&gt;Probability of Composed Events&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;The complement of an event can be computed from the probability of the event.&lt;/li&gt;
  &lt;li&gt;The union of events can be computed from the probabilities of the individual events.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;complement&quot;&gt;Complement&lt;/h3&gt;
&lt;p&gt;Let $\neg E = S - E$. Then $P(\neg E)=1-P(E)$&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img/COMP111201118-2.md.5324.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Additionally, $S=\neg E\cup E$.&lt;/p&gt;

&lt;h4 id=&quot;proof&quot;&gt;Proof&lt;/h4&gt;
&lt;p&gt;\(1=\sum_{x\in S}P(x)=\sum_{x\in E}P(x)+\sum_{x\in \neg E}P(x)\)&lt;/p&gt;

&lt;p&gt;Thus,&lt;/p&gt;

\[\sum_{x\in\neg E}P(x)=1-\sum_{x\in E}P(x)\]

&lt;h4 id=&quot;example&quot;&gt;Example&lt;/h4&gt;
&lt;p&gt;What is the probability that at least one bit in a randomly generated sequence of 10 bits is 0?&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$S = {0, 1}^{10} =$ all sequences of 0 and 1 of length 10.&lt;/li&gt;
  &lt;li&gt;For every $x ∈ S, P(x) = (\frac{1}{2})^{10} = \frac{1}{2^{10}}$.&lt;/li&gt;
  &lt;li&gt;$E =$ all sequences of 0 and 1 of length 10 containing at least one 0.&lt;/li&gt;
  &lt;li&gt;$\neg E={1111111111}$&lt;/li&gt;
  &lt;li&gt;$P(\neg E)=\frac{1}{2^{10}}$&lt;/li&gt;
  &lt;li&gt;$P(E)=1-\frac{1}{2^{10}}$&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;union&quot;&gt;Union&lt;/h3&gt;
&lt;p&gt;\(P(E_1\cup U_2)=P(E_1)+P(E_2)-P(E_1\cap E_2)\)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;img/COMP111201118-2.md.8606.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Additionally, $&lt;/td&gt;
      &lt;td&gt;E_1\cup E_2&lt;/td&gt;
      &lt;td&gt;=&lt;/td&gt;
      &lt;td&gt;E_1&lt;/td&gt;
      &lt;td&gt;+&lt;/td&gt;
      &lt;td&gt;E_2&lt;/td&gt;
      &lt;td&gt;-&lt;/td&gt;
      &lt;td&gt;E_1\cap E_2&lt;/td&gt;
      &lt;td&gt;$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&quot;proof-1&quot;&gt;Proof&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;$P(E_1)=\sum_{x\in E_1}P(x)$&lt;/li&gt;
  &lt;li&gt;$P(E_2)=\sum_{x\in E_2}P(x)$&lt;/li&gt;
  &lt;li&gt;$P(E_1\cup E_2)=\sum_{x\in E_1\cup E_2}P(x)$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Thus,&lt;/p&gt;

&lt;p&gt;$P(E_1\cup E_2)=\sum_{x\in E_1\cup E_2}P(x)$&lt;/p&gt;

&lt;p&gt;$=\sum_{x\in E_1}P(x)+\sum_{x\in E_3}P(x)-\sum_{x\in E_1\cup E_2}P(x)$&lt;/p&gt;

&lt;p&gt;$=P(E_1)+P(E_2)-P(E_1\cap E_2)$&lt;/p&gt;

&lt;h4 id=&quot;example-1&quot;&gt;Example&lt;/h4&gt;
&lt;p&gt;Suppose I have a jar of 30 sweets:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt; &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Red&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Blue&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Green&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Circular&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Square&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;6&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;7&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;8&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The sample space $S$ has 30 elements and if one chooses a sweet uniformly at random then then the probability for all $x\in S$ is:&lt;/p&gt;

\[P(x)=\frac{1}{30}\]

&lt;p&gt;What is the probability of choosing a red or circular sweet?&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The probability that it is red is $\frac{2+6}{30}=\frac{8}{30}(P(R)=\frac{8}{30})$&lt;/li&gt;
  &lt;li&gt;The probability that it is cicular is $\frac{2+4+3}{30}=\frac{9}{30}(P(C)=\frac{9}{30})$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Then $P(R\cup C)$ is the probability that the sweet is red or circular:&lt;/p&gt;

\[P(R\cup C) = P(R)+P(C)-P(R\cap C) = \frac{8}{30}+\frac{9}{30}-\frac{2}{30}=\frac{15}{30}=\frac{1}{2}\]</content><author><name>Ben Weston</name><email>b.weston60@gmail.com</email></author><category term="COMP111" /><category term="Lectures" /><category term="COMP111" /><category term="Lectures" /><summary type="html">An event is a subset $E ⊆ S$ of the sample space $S$. The probability of the even $E$ is given by: \[P(E)=\sum_{x\in E}P(x)\] $0 ≤ P(E) ≤ 1$ for every event $E$ $P(\emptyset) = 0$ and $P(S) = 1$ Example - Fair Dice If I roll a die three times, the event $E$ of rolling at least one 6 is given by: The set of sequences of length 4 over ${1,\ldots,6}$ containing at least one 6. $P(E)$ is the number of sequences containing at least one 6 divided by $6\times6\times6\times6=216$. If we roll a fair die, then the event E of rolling an odd number is given by: The set $E={1,3,5}$ $P(E)=P(1)+P(3)+P(5)=\frac{1}{6}+\frac{1}{6}+\frac{1}{6}=\frac{1}{2}$ Probability of Composed Events The complement of an event can be computed from the probability of the event. The union of events can be computed from the probabilities of the individual events. Complement Let $\neg E = S - E$. Then $P(\neg E)=1-P(E)$ Additionally, $S=\neg E\cup E$. Proof \(1=\sum_{x\in S}P(x)=\sum_{x\in E}P(x)+\sum_{x\in \neg E}P(x)\) Thus, \[\sum_{x\in\neg E}P(x)=1-\sum_{x\in E}P(x)\] Example What is the probability that at least one bit in a randomly generated sequence of 10 bits is 0? $S = {0, 1}^{10} =$ all sequences of 0 and 1 of length 10. For every $x ∈ S, P(x) = (\frac{1}{2})^{10} = \frac{1}{2^{10}}$. $E =$ all sequences of 0 and 1 of length 10 containing at least one 0. $\neg E={1111111111}$ $P(\neg E)=\frac{1}{2^{10}}$ $P(E)=1-\frac{1}{2^{10}}$ Union \(P(E_1\cup U_2)=P(E_1)+P(E_2)-P(E_1\cap E_2)\) Additionally, $ E_1\cup E_2 = E_1 + E_2 - E_1\cap E_2 $ Proof $P(E_1)=\sum_{x\in E_1}P(x)$ $P(E_2)=\sum_{x\in E_2}P(x)$ $P(E_1\cup E_2)=\sum_{x\in E_1\cup E_2}P(x)$ Thus, $P(E_1\cup E_2)=\sum_{x\in E_1\cup E_2}P(x)$ $=\sum_{x\in E_1}P(x)+\sum_{x\in E_3}P(x)-\sum_{x\in E_1\cup E_2}P(x)$ $=P(E_1)+P(E_2)-P(E_1\cap E_2)$ Example Suppose I have a jar of 30 sweets:   Red Blue Green Circular 2 4 3 Square 6 7 8 The sample space $S$ has 30 elements and if one chooses a sweet uniformly at random then then the probability for all $x\in S$ is: \[P(x)=\frac{1}{30}\] What is the probability of choosing a red or circular sweet? The probability that it is red is $\frac{2+6}{30}=\frac{8}{30}(P(R)=\frac{8}{30})$ The probability that it is cicular is $\frac{2+4+3}{30}=\frac{9}{30}(P(C)=\frac{9}{30})$ Then $P(R\cup C)$ is the probability that the sweet is red or circular: \[P(R\cup C) = P(R)+P(C)-P(R\cap C) = \frac{8}{30}+\frac{9}{30}-\frac{2}{30}=\frac{15}{30}=\frac{1}{2}\]</summary></entry><entry><title type="html">COMP111 - Probability of the Union of Events</title><link href="http://localhost:4000/UoL/comp111/lectures/2020/11/18/3.html" rel="alternate" type="text/html" title="COMP111 - Probability of the Union of Events" /><published>2020-11-18T00:00:00+00:00</published><updated>2020-11-18T00:00:00+00:00</updated><id>http://localhost:4000/UoL/comp111/lectures/2020/11/18/3</id><content type="html" xml:base="http://localhost:4000/UoL/comp111/lectures/2020/11/18/3.html">&lt;h2 id=&quot;disjoint-events&quot;&gt;Disjoint Events&lt;/h2&gt;
&lt;p&gt;Assume that $E _1,\ldots,E_n$ are mutually disjoint events. So $E_i\cap E_j=\emptyset$ whenever $i\neq j$.&lt;/p&gt;

&lt;p&gt;Then,&lt;/p&gt;

\[P(\bigcup_{i\leq i \leq n}E_i)=\sum_{1\leq i\leq n}P(E_i)\]

&lt;h3 id=&quot;example---three-dice&quot;&gt;Example - Three Dice&lt;/h3&gt;
&lt;p&gt;Suppose that I roll a fair die three times:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$S$ is the set of dequences of lengh three over ${1,\ldots,6}$ (or ${1,\ldots,6}^3$).&lt;/li&gt;
  &lt;li&gt;$P(x)=\frac{1}{6\times6\times6}=\frac{1}{216}$ for all $x\in S$.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;What is the probability that I roll at least one 6?&lt;/p&gt;

&lt;p&gt;Let $E_1$: even that 1^st roll is a 6, $E_2$: event that 2^nd roll is a 6; $E_3$: event that 3^rd roll is a 6.&lt;/p&gt;

&lt;p&gt;This means that we would like to know:&lt;/p&gt;

\[P(E_1\cup E_2 \cup E_3)\]

&lt;h4 id=&quot;computing-the-probability-of-a-union-of-three-sets&quot;&gt;Computing the Probability of a Union of Three Sets&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;$P(A\cup B \cup C)=P(A)+P(B)+P(C)$&lt;/li&gt;
  &lt;li&gt;$-P(A\cap B)-P(A\cap C)- P(B\cap C)$&lt;/li&gt;
  &lt;li&gt;$+P(A\cap B \cap C)$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;img/COMP111201118-3.md.3413.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Additionally:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;$&lt;/td&gt;
          &lt;td&gt;A\cup B \cup C&lt;/td&gt;
          &lt;td&gt;=&lt;/td&gt;
          &lt;td&gt;A&lt;/td&gt;
          &lt;td&gt;+&lt;/td&gt;
          &lt;td&gt;B&lt;/td&gt;
          &lt;td&gt;+&lt;/td&gt;
          &lt;td&gt;C&lt;/td&gt;
          &lt;td&gt;$&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;$-&lt;/td&gt;
          &lt;td&gt;A\cap B&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;A\cap C&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
          &lt;td&gt;B\cap C&lt;/td&gt;
          &lt;td&gt;$&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;$+&lt;/td&gt;
          &lt;td&gt;A\cap B \cap C&lt;/td&gt;
          &lt;td&gt;$&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;example-continued&quot;&gt;Example Continued&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;$E_1$: even that 1^st roll is a 6.&lt;/li&gt;
  &lt;li&gt;$E_2$: event that 2^nd roll is a 6.&lt;/li&gt;
  &lt;li&gt;$E_3$: event that 3^rd roll is a 6.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We can calculate the answer with the equation from earlier:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$P(E_1\cup E_2 \cup E_3)=P(E_1)+P(E_2)+P(E_3)$&lt;/li&gt;
  &lt;li&gt;$-P(E_1\cap E_2)-P(E_1\cap E_3)- P(E_2\cap E_3)$&lt;/li&gt;
  &lt;li&gt;$+P(E_1\cap E_2 \cap E_3)$&lt;/li&gt;
  &lt;li&gt;$=\frac{36}{216}+\frac{36}{216}+\frac{36}{216}$&lt;/li&gt;
  &lt;li&gt;$-\frac{6}{216}-\frac{6}{216}-\frac{6}{216}$&lt;/li&gt;
  &lt;li&gt;$+\frac{1}{216}$&lt;/li&gt;
  &lt;li&gt;$=\frac{91}{216}\approx0.42$&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Ben Weston</name><email>b.weston60@gmail.com</email></author><category term="COMP111" /><category term="Lectures" /><category term="COMP111" /><category term="Lectures" /><summary type="html">Disjoint Events Assume that $E _1,\ldots,E_n$ are mutually disjoint events. So $E_i\cap E_j=\emptyset$ whenever $i\neq j$. Then, \[P(\bigcup_{i\leq i \leq n}E_i)=\sum_{1\leq i\leq n}P(E_i)\] Example - Three Dice Suppose that I roll a fair die three times: $S$ is the set of dequences of lengh three over ${1,\ldots,6}$ (or ${1,\ldots,6}^3$). $P(x)=\frac{1}{6\times6\times6}=\frac{1}{216}$ for all $x\in S$. What is the probability that I roll at least one 6? Let $E_1$: even that 1^st roll is a 6, $E_2$: event that 2^nd roll is a 6; $E_3$: event that 3^rd roll is a 6. This means that we would like to know: \[P(E_1\cup E_2 \cup E_3)\] Computing the Probability of a Union of Three Sets $P(A\cup B \cup C)=P(A)+P(B)+P(C)$ $-P(A\cap B)-P(A\cap C)- P(B\cap C)$ $+P(A\cap B \cap C)$ Additionally: $ A\cup B \cup C = A + B + C $ $- A\cap B - A\cap C - B\cap C $ $+ A\cap B \cap C $ Example Continued $E_1$: even that 1^st roll is a 6. $E_2$: event that 2^nd roll is a 6. $E_3$: event that 3^rd roll is a 6. We can calculate the answer with the equation from earlier: $P(E_1\cup E_2 \cup E_3)=P(E_1)+P(E_2)+P(E_3)$ $-P(E_1\cap E_2)-P(E_1\cap E_3)- P(E_2\cap E_3)$ $+P(E_1\cap E_2 \cap E_3)$ $=\frac{36}{216}+\frac{36}{216}+\frac{36}{216}$ $-\frac{6}{216}-\frac{6}{216}-\frac{6}{216}$ $+\frac{1}{216}$ $=\frac{91}{216}\approx0.42$</summary></entry></feed>